{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Chapter Two\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"my path is \", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup 0⃣\n",
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "Your first task is to use California census data to build a model of housing prices in the state. This data includes metrics such as the population, median income, and median housing price for each\n",
    "dstrict in California. Your model should learn from this data and be able to predict the median housing price in any district, given all the other metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Project Checklist\n",
    " \n",
    "1. Look at the big picture.\n",
    "2. Get the data.\n",
    "3. Discover and visualize the data to gain insights.\n",
    "4. Prepare the data for Machine Learning algorithms.\n",
    "5. Select a model and train it.\n",
    "6. Fine-tune your model.\n",
    "7. Present your solution.\n",
    "8. Launch, monitor, and maintain your system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Frame the problem and look at the big picture\n",
    "Model's output, a prediction of district's median housing price, will be ged to another ML system (pipeline) along with other information which will determine whether it is worth investing in the area or not.\n",
    "\n",
    "Ask yourself, is this a Supervised, Unsupervised, or Reinforcement Learning problem? Is it a calssification task, regression task, or something else? Should you use batch learning, online learning, or something else?\n",
    "\n",
    "1. Supervised\n",
    "- Regression: predicting a value\n",
    "- Classification: Predict a class\n",
    "2. Unsupervised\n",
    "- Clustering: Group ungrouped data\n",
    "- Assocation Rule Mining: Find associations between two or more classes\n",
    "3. Reinforcement\n",
    "- Supervised univariate regression task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that fetches housing.tgz data\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "#creates a datasets/housing directory in your workspace, downloads the housing.tgz file, and extracts the housing.csv file from it in this directory\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "    \n",
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data using pandas\n",
    "import pandas as pd\n",
    "\n",
    "#returns a pandas DataFrame object containing all the data\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view top five rows in the dataset using head()\n",
    "#10 attributes\n",
    "housing = load_housing_data()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a quick description of the data using info()\n",
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only ocean_proximity is an object, but we know it is text since this is loaded from a CSV file\n",
    "#find out what categories exist and how many districts belong to each category using value_counts()\n",
    "print(housing[\"ocean_proximity\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary of numerical attributes using describe() to get a feel for the data\n",
    "housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a histogram to get a feel for the data\n",
    "#plot a histogram for each numerical attribute. A histogram shows the number of instances (on the vertical axis) that have a given value range (on the horizontal axis).\n",
    "#specify which backend Matplotlib, tells Jupyter to set up Matplotlib so it uses Jupyter’s own backend.\n",
    "# only in a Jupyter notebook\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "housing.hist(bins=50, figsize=(20,15))\n",
    "#optional in a Jupyter notebook, as Jupyter will automatically display plots when a cell is executed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a test set\n",
    "Pick instances randomly, typically %20 of the testset. Don't look at data too much before setting aside some training data even before choosing an algorithm to avoid your own biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    " shuffled_indices = np.random.permutation(len(data))\n",
    " test_set_size = int(len(data) * test_ratio)\n",
    " test_indices = shuffled_indices[:test_set_size]\n",
    " train_indices = shuffled_indices[test_set_size:]\n",
    " return data.iloc[train_indices], data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can then use your function like this\n",
    "train_set, test_set = split_train_test(housing, 0.2)\n",
    "print(\"train_set: \", len(train_set))\n",
    "print(\"test_set: \", len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This works but will generate a different test set with each run\n",
    "#compute a hash of each instance’s identifier and put that instance in the test set if the hash is lower than or equal to \n",
    "#20% of the maximum hash value. This ensures that the test set will remain consistent across multiple runs, even if you refresh the dataset.\n",
    "#The new test set will contain 20% of the new instances, but it will not contain any instance that was previously in the training set.\n",
    "from zlib import crc32\n",
    "\n",
    "def test_set_check(identifier, test_ratio):\n",
    " return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
    "\n",
    "def split_train_test_by_id(data, test_ratio, id_column):\n",
    " ids = data[id_column]\n",
    " in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n",
    " return data.loc[~in_test_set], data.loc[in_test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adds an `index` column\n",
    "# housing_with_id[\"id\"] = housing[\"longitude\"] * 1000 + housing[\"latitude\"]\n",
    "# train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adds an 'index' column with sklearn with more features than above\n",
    "#random_state parameter that allows you to set the random generator seed\n",
    "#can pass it multiple datasets with an identical number of rows, and it will split them on the same indices \n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To reduce sampling bias, we implement strata samplying and ensure our data includes the median income to accurately predict median home prices\n",
    "#using the pd.cut() function to create an income category attribute with five categories (labeled from 1 to 5): category 1 ranges from 0 to 1.5 \n",
    "#(i.e., less than $15,000), category 2 from 1.5 to 3, etc\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"], bins=[0., 1.5, 3.0, 4.5, 6., np.inf], labels=[1, 2, 3, 4, 5])\n",
    "housing[\"income_cat\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratified sampling based on the income category using Scikit-Learn’s StratifiedShuffleSplit class:\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "#n_splits=Number of re-shuffling & splitting iterations.\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    " strat_train_set = housing.loc[train_index]\n",
    " strat_test_set = housing.loc[test_index]\n",
    "#look at income category proportions in the test set\n",
    "print(strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the income_cat attribute so the data is back to its original state since sampling is skewed\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    " set_.drop(\"income_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover and Visualize the Data to Gain Insights\n",
    "- Make sure you have put aside your test set and are only exploring the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy training set to play with so we do not harm the training data we have put aside\n",
    "housing = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Geographical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")\n",
    "#set alpha option to visualize the places where there is a high density of data points\n",
    "# the alpha parameter controls the opacity of the points in the plot. The value of alpha ranges from 0 to 1, where 0 means completely transparent (the points are invisible), and 1 means completely opaque\n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now look at housing prices\n",
    "#each radius represents the district's population (s), color represents price (c)\n",
    "#use predefined  color map (cmap)\n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4, s=housing[\"population\"]/100, label=\"population\", figsize=(10,7), c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the California image\n",
    "images_path = os.path.join(PROJECT_ROOT_DIR, \"images\", \"end_to_end_project\")\n",
    "os.makedirs(images_path, exist_ok=True)\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "filename = \"california.png\"\n",
    "print(\"Downloading\", filename)\n",
    "url = DOWNLOAD_ROOT + \"images/end_to_end_project/\" + filename\n",
    "urllib.request.urlretrieve(url, os.path.join(images_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "california_img=mpimg.imread(os.path.join(images_path, filename))\n",
    "ax = housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", figsize=(10,7),\n",
    "                  s=housing['population']/100, label=\"Population\",\n",
    "                  c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"),\n",
    "                  colorbar=False, alpha=0.4)\n",
    "plt.imshow(california_img, extent=[-124.55, -113.80, 32.45, 42.05], alpha=0.5,\n",
    "           cmap=plt.get_cmap(\"jet\"))\n",
    "plt.ylabel(\"Latitude\", fontsize=14)\n",
    "plt.xlabel(\"Longitude\", fontsize=14)\n",
    "\n",
    "prices = housing[\"median_house_value\"]\n",
    "tick_values = np.linspace(prices.min(), prices.max(), 11)\n",
    "cbar = plt.colorbar(ticks=tick_values/prices.max())\n",
    "cbar.ax.set_yticklabels([\"$%dk\"%(round(v/1000)) for v in tick_values], fontsize=14)\n",
    "cbar.set_label('Median House Value', fontsize=16)\n",
    "\n",
    "plt.legend(fontsize=16)\n",
    "save_fig(\"california_housing_prices_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking for Correlations  \n",
    "between attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute standard correlation coefficient (Pearson's r) between every pair of attributes using corr()\n",
    "corr_matrix = housing.corr(numeric_only=True)\n",
    "#look at how each attribute correlates with median house value\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation coefficient ranges from –1 to 1. When it is close to 1, it means that\n",
    "there is a strong positive correlation; for example, the median house value tends to go\n",
    "up when the median income goes up. When the coefficient is close to –1, it means\n",
    "that there is a strong negative correlation; you can see a small negative correlation\n",
    "between the latitude and the median house value (i.e., prices have a slight tendency to\n",
    "go down when you go north). Finally, coefficients close to 0 mean that there is no\n",
    "linear correlation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another way to check for correlation between attributes is scatter_matrix()\n",
    "#which plots every numerical attribute against every other numerical attribute\n",
    "#limit to promising attributes!\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
    "              \"housing_median_age\"]\n",
    "scatter_matrix(housing[attributes], figsize=(12, 8))\n",
    "save_fig(\"scatter_matrix_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zoom in on the most promising attribute, median income\n",
    "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot reveals a few things. First, the correlation is indeed very strong; you can clearly see the upward trend, and the points are not too dispersed. Second, the price cap that we noticed earlier is clearly visible as a horizontal line at $500,000. But this plot reveals other less obvious straight lines: a horizontal line around $450,000, another around $350,000, perhaps one around $280,000, and a few more below that. You may want to try removing the corresponding districts to prevent your algorithms from learning to reproduce these data quirks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you want to experiment a little more with attribute combinations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine some attributes\n",
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]\n",
    "#look at the correlation matrix again:\n",
    "corr_matrix = housing.corr(numeric_only=True)\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"rooms_per_household\", y=\"median_house_value\",\n",
    "             alpha=0.2)\n",
    "plt.axis([0, 5, 0, 520000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new bedrooms_per_room attribute is much more correlated with the median house value than the total number of rooms or bedrooms. Apparently houses with a lower bedroom/room ratio tend to be more expensive. The number of rooms per household is also more informative than the total number of rooms in a district—obviously the larger the houses, the more expensive they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare the data for Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#revert to a clean training set\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1) # drop labels for training set\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "Most Machine Learning algorithms cannot work with missing features, so let’s create\n",
    "a few functions to take care of them. We saw earlier that the total_bedrooms\n",
    "attribute has some missing values, so let’s fix this. You have three options:\n",
    "1. Get rid of the corresponding districts.\n",
    "2. Get rid of the whole attribute.\n",
    "3. Set the values to some value (zero, the mean, the median, etc.).\n",
    "   \n",
    "You can accomplish these easily using DataFrame’s dropna(), drop(), and fillna()\n",
    "methods:\n",
    "- housing.dropna(subset=[\"total_bedrooms\"]) # option 1\n",
    "- housing.drop(\"total_bedrooms\", axis=1) # option 2\n",
    "- median = housing[\"total_bedrooms\"].median() # option 3\n",
    "  \n",
    "housing[\"total_bedrooms\"].fillna(median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use SimpleImputer to take care of missing values by replacing each missing value with the median of that attribute\n",
    "from sklearn.impute import SimpleImputer\n",
    "#imputer will replace missing values with the mean, median, most frequent, etc of the column\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "#Since the median can only be computed on numerical attributes create a copy of the data without the text attribute ocean_proximity\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "imputer.fit(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imputer.statistics_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that thi is the same as manually computing the median of each attribute\n",
    "#commenting out since I get error: TypeError: 'Categorical' with dtype category does not support reduction 'median'\n",
    "#housing_num.median().values\n",
    "#using this instead\n",
    "housing_num_only = housing_num.select_dtypes(include=[np.number])\n",
    "housing_num_only.median().values\n",
    "#I get the same values I should except on the last one which is nly a little off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now use the trained imputer to transform the training set by replacing missing values with learned medians\n",
    "X = imputer.transform(housing_num)\n",
    "#transofrm play NumPy array to DataFrame\n",
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns, index=housing_num.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Text and Categorical Attributes\n",
    "Only one here is the ocean_proximity attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling Text Attributes\n",
    "housing_cat = housing[[\"ocean_proximity\"]]\n",
    "#look at first ten instances\n",
    "housing_cat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Algorithms prefer to work with numbers, so convert text to numbers\n",
    "#Convert text to numbers for Machine Learning Algorithms using OrdinalEncoder class\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "housing_cat_encoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of 1D list of categories for each categorical attribute using categories_ instance variable\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML algorithms will assume that two nearby values are more similar than two distant values. This may be fine in some cases (e.g.,\n",
    "#for ordered categories such as “bad,” “average,” “good,” and “excellent”), but it is obviously not the case for the ocean_proximity column\n",
    "#(for example, categories 0 and 4are clearly more similar than categories 0 and 1). To fix this issue, a common solution is to create one binary\n",
    "#attribute per category: one attribute equal to 1 when the category is “<1H OCEAN” (and 0 otherwise), another attribute equal to 1 when the cate‐\n",
    "#gory is “INLAND” (and 0 otherwise), and so on. This is called one-hot encoding, because only one attribute will be equal to 1 (hot), while the \n",
    "#others will be 0 (cold). The new attributes are sometimes called dummy attributes. Uses oneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot\n",
    "#or to convert to a dense NumPy array\n",
    "#housing_cat_1hot.toarray()\n",
    "cat_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Transformers\n",
    "Although Scikit-Learn provides many useful transformers, you will need to write your own for tasks such as custom cleanup operations or combining specific attributes. You will want your transformer to work seamlessly with Scikit-Learn functionalities (such as pipelines), and since Scikit-Learn relies on duck typing (not inheritance), all you need to do is create a class and implement three methods: fit()\n",
    "(returning self), transform(), and fit_transform().\n",
    "\n",
    "You can get the last one for free by simply adding TransformerMixin as a base class. If you add BaseEstimator as a base class (and avoid *args and **kargs in your constructor), you will also get two extra methods (get_params() and set_params()) that will be useful for automatic hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example: this is a small transformer class that adds the combined attributes discussed earlier;\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    " def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
    "     self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    " def fit(self, X, y=None):\n",
    "     return self # nothing else to do\n",
    " def transform(self, X):\n",
    "     rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "     population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "     if self.add_bedrooms_per_room:\n",
    "         bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "         return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "     else:\n",
    "        return np.c_[X, rooms_per_household, population_per_household]\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "Not generally required. \n",
    "\n",
    "One of the most important transformations you need to apply to your data is feature scaling. With few exceptions, Machine Learning algorithms don’t perform well when the input numerical attributes have very different scales. This is the case for the housing data: the total number of rooms ranges from about 6 to 39,320, while the median incomes only range from 0 to 15. Note that scaling the target values is generally not required. There are two common ways to get all attributes to have the same scale: min-max scaling and standardization.\n",
    "\n",
    "1. Min-max Scaling\n",
    "  - Min-max scaling (normalization) is the simplest: values are shifted and rescaled so that they end up ranging from 0 to 1. We do this by subtracting the min value and dividing by the max minus the min. Scikit-Learn provides a transformer called MinMaxScaler for this. It has a feature_range hyperparameter that lets you change the range if, for some reason, you don’t want 0–1.\n",
    "2. Standardization\n",
    "- first it subtracts the mean value (so standardized values always have a zero mean), and then it divides by the standard deviation so that the resulting distribution has unit variance. Unlike min-max scaling, standardization does not bound values to a specific range, which may be a problem for some algorithms (e.g., neural networks often expect an input value ranging from 0 to 1). However, standardization is much less affected by outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranformation Pipelines\n",
    "Data transformation steps that need to be executed in the right order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are many data transformation steps that need to be executed in the right order. Fortunately, Scikit-Learn provides the Pipeline class to help with such sequences of transformations. \n",
    "#Here is a small pipeline for the numerical attributes:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "num_pipeline = Pipeline([\n",
    " ('imputer', SimpleImputer(strategy=\"median\")),\n",
    " ('attribs_adder', CombinedAttributesAdder()),\n",
    " ('std_scaler', StandardScaler()),\n",
    " ])\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "#All but the last estimator must be transformers (i.e., they must have a fit_transform() method)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you call the pipeline’s fit() method, it calls fit_transform() sequentially on all transformers, passing the output of each call as the parameter to the next call until it reaches the final estimator, for which it calls the fit() method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have handled the categorical columns and the numerical columns separately. It would be more convenient to have a single transformer able to handle all columns, applying the appropriate transformations to each column. Let’s Scikit-Learn's ColumnTransformerto apply all the transformations to the housing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply all the transformations to the housing data\n",
    "#import ColumnTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "#get a list of categorical column names\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "#construct  ColumnTransformer\n",
    "#constructor requires a list of tuples, where each tuple contains a name,22 a transformer, and a list of names (or indices) of columns that the transformer should be applied to.\n",
    "full_pipeline = ColumnTransformer([\n",
    " (\"num\", num_pipeline, num_attribs),\n",
    " (\"cat\", OneHotEncoder(), cat_attribs),\n",
    " ])\n",
    "# apply this ColumnTransformer to the housing data: it applies each transformer to the appropriate columns and concatenates the outputs along the second axis\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and Train a Model\n",
    "At last! You framed the problem, you got the data and explored it, you sampled a training set and a test set, and you wrote transformation pipelines to clean up and prepare your data for Machine Learning algorithms automatically. You are now ready to select and train a Machine Learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluating on the Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try a Linear Regression Model\n",
    "- Supervised Learning Algorithm\n",
    "- Used to Predict Values\n",
    "- Simplest and most commonly used\n",
    "- typically use a cost function that measures the distance between the linear model’s predictions and the training examples; the objective is to minimize this distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first train a Linear Regression model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a working Linear Regression model. Let's try it on a few instances from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try the Linear Regression model out on a few instances from training set\n",
    "some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "print(\"Predictions:\", lin_reg.predict(some_data_prepared))\n",
    "print(\"Labels:\", list(some_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions are not exactly accurate (e.g., the first prediction is off by close to 40%!). Let’s measure this regression model’s RMSE on the whole training set using Scikit-Learn’s mean_squared_error() function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure this regression model’s RMSE on the whole training set using mean_squared_error() function\n",
    "from sklearn.metrics import mean_squared_error\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most districts’ median_housing_values range between $120,000 and $265,000, so a typical prediction error of $68,628 is not very satisfying. \n",
    "This is an example of a model underfitting the training data. So, features do not provide enough info to make good predictions.\n",
    "\n",
    "Let's train DecisionTreeRegressor, which is a more powerful model capable of finding nonlinear relationships in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a DecisionTreeRegressor. This is a powerful model, capable of finding complex nonlinear relationships in the data \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that the model is trained, let’s evaluate it on the training set:\n",
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model too perfect (0.0 means no error at all), we may have overfit the model now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better Evaluation Using Cross-Validation\n",
    "Evaluate the model using Cross-Validation. This code randomly splits the training set into 10 distinct subsets called folds, then it trains and evaluates the Decision Tree model 10 times, picking a different fold for evaluation every time and training on the other 9 folds. The result is an array containing the 10 evaluation scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use K-fold cross-validation feature. The following code randomly splits the training set into 10 distinct subsets called folds, then it\n",
    "#trains and evaluates the Decision Tree model 10 times, picking a different fold for evaluation every time and training on the other 9 folds. \n",
    "#The result is an array containing the 10 evaluation scores:\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
    " scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "#print\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree model is overfitting so badly that it performs worse than the Linear Regression model. Notice that cross-validation allows you to get not only an estimate of the performance of your model, but also a measure of how precise this estimate is (i.e., its standard deviation). The Decision Tree has a score of approximately 71,407, generally ±2,439."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the same scores for the Linear Regression model just to be sure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try RandomForestRegressor model\n",
    "#works by training many Decision Trees on random subsets of the features, then averaging out their predictions. Building a model on top of many\n",
    "#other models is called Ensemble Learning, and it is often a great way to push ML algorithms even further\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "forest_reg.fit(housing_prepared, housing_labels)\n",
    "housing_predictions = forest_reg.predict(housing_prepared)\n",
    "forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, this is much better: Random Forests look very promising. However, note that the score on the training set is still much lower than on the validation sets, meaning that the model is still overfitting the training set. Possible solutions for overfitting are to simplify the model, constrain it (i.e., regularize it), or get a lot more training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune Your Model\n",
    "Let’s assume that you now have a shortlist of promising models. You now need to fine-tune them. Let’s look at a few ways you can do that.\n",
    "1. Grid Search (GridSearchSV): \n",
    "- To find best hyperparameters.\n",
    "- With GridSearchSV all you need to do is tell it which hyperparameters you want it to experiment with and what values to try out, and it will use cross-validation to evaluate all the possible combinations of hyperparameter values.\n",
    "2. Randomized Search\n",
    "- Better for when the hyperparameter space is large\n",
    "- RandomizedSearchCV works much like gridSearchSV, but instead of trying out all possible combinations it evaluates a given number of random combos by selecting a random value with each hyperparameter at every iteration\n",
    "3. Ensemble Methods\n",
    "- combine models that perform best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following code searches for the best combination of hyperparameter values for the RandomForestRegressor:\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#first evaluate all 3 × 4 = 12 combinations of n_estimators and max_features hyperparameter values specified in the first dict then try all 2 × 3 = 6 combinations of hyperparameter \n",
    "#values in the second dict, but this time with the bootstrap hyperparameter set to False instead of True (which is the default value for this hyperparameter)\n",
    "param_grid = [\n",
    " {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    " {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    " ]\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    " scoring='neg_mean_squared_error',\n",
    "return_train_score=True)\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "#The grid search will explore 12 + 6 = 18 combinations of RandomForestRegressor hyperparameter values, and it will train each model 5 times (since we are using five-fold \n",
    "#cross validation). In other words, all in all, there will be 18 × 5 = 90 rounds of training\n",
    "\n",
    "#Since 8 and 30 are the maximum values that were evaluated, you should probably try searching again with higher values; the score may continue to improve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best combination of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get the best estimator directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#??\n",
    "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    " max_features=8, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    " min_samples_leaf=1,\n",
    " min_weight_fraction_leaf=0.0,\n",
    " n_estimators=30, n_jobs=None, oob_score=False, random_state=None,\n",
    " verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation scores are also available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "  print(np.sqrt(-mean_score), params)\n",
    "  \n",
    "#so RMSe score for best estimators is 50,800 which is better than what we got earlier. Model is now fine tuned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the Best Models and Their Errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will often gain good insights on the problem by inspecting the best models. For example, the RandomForestRegressor can indicate the relative importance of each attribute for making accurate predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s display these importance scores next to their corresponding attribute names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this information, you may want to try dropping some of the less useful features (e.g., apparently only one ocean_proximity category is really useful, so you could try dropping the others).\n",
    "You should also look at the specific errors that your system makes, then try to understand why it makes them and what could fix the problem (adding extra features or getting rid of uninformative ones, cleaning up outliers, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Your System on the Test Set\n",
    "Just get the predictors and the labels from your test set, run your full_pipeline to transform the data (call transform(), not fit_transform()—you do not want to fit the test set!), and evaluate the final model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse) # => evaluates to 47,730.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, such a point estimate of the generalization error will not be quite enough to convince you to launch: what if it is just 0.1% better than the model currently in production? You might want to have an idea of how precise this estimate is. For this, you can compute a 95% confidence interval for the generalization error using scipy.stats.t.interval():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "confidence = 0.95\n",
    "squared_errors = (final_predictions - y_test) ** 2\n",
    "np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1, loc=squared_errors.mean(), scale=stats.sem(squared_errors)))\n",
    "\n",
    "#If you did a lot of hyperparameter tuning, the performance will usually be slightly worse than what you measured using cross-validation (because your system ends up fine-tuned to \n",
    "#perform well on the validation data and will likely not perform as well  on unknown datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Chapter 2, Exercise 1\n",
    "Try a Support Vector Machine regressor (`sklearn.svm.SVR`) with various hyperparameters, such as `kernel=\"linear\"` (with various values for the C hyperparameter) or `kernel=\"rbf\"` \n",
    "(with various values for the `C` and `gamma` hyperparameters). Don’t worry about what these hyperparameters mean for now. How does the best SVR predictor perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train SVC model\n",
    "from sklearn.svm import SVC\n",
    "#Cfloat, default=1.0 Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty.\n",
    "sup_vec = SVC()\n",
    "#(X, y[, sample_weight]) Fit the SVM model according to the given training data.\n",
    "sup_vec.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The C value balances the decision boundary's margin width and the classification error on the training data. Higher C values will minimize classification error. This can lead to a model that fits the training data very well, including outliers and noise, potentially causing overfitting. Lower C values encourages the model to find a decision boundary with a wider margin, even if that boundary misclassifies more points. This may cause a simpler model that may generalize better on unseen data, but at the risk of underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(X) Perform classification on samples in X.\n",
    "housing_predictions = sup_vec.predict(housing_prepared)\n",
    "#(y_true, y_pred) y_true:array-like of shape (n_samples,) or (n_samples, n_outputs) Ground truth (correct) target values.\n",
    "#y_pred: array-like of shape (n_samples,) or (n_samples, n_outputs)Estimated target values.\n",
    "svc_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "svc_rmse = np.sqrt(svc_mse)\n",
    "svc_rmse #182221.07908782372\n",
    "#took 58 minutes\n",
    "#45 minutes on CMIX server 10805\n",
    "#took 50 minutes using free Colab GPU\n",
    "#took 48 minutes on CMIX server 10802 (using old machine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is 182,221 units away from the actual values in the dataset, so a significant deviation in predicted house prices from actual house prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE is a standard way to measure the error of a model in predicting quantitative data. It quantifies how much the predicted values (in this case, housing_predictions) deviate from the actual values (housing_labels), providing a comprehensive measure of prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC #COMMENT OUT\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'kernel': ['linear', 'rbf'],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]} #SCALE AND AUTO?\n",
    "#initialize GridSearchCV\n",
    "grid_search = GridSearchCV(sup_vec, param_grid, cv=5)\n",
    "#Fit GridSeachCV to training data\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does the best SVR Predictor perform?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2, Exercise 2\n",
    "Try replacing GridSearchCV with RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'kernel': ['linear', 'rbf'],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100, 'scale', 'auto']} \n",
    "#initialize RandomizedSearchCV\n",
    "rand_search = RandomizedSearchCV(sup_vec, param_grid, cv=5)\n",
    "#Fit RandomizedSearchCV to training data\n",
    "rand_search.fit(housing_prepared, housing_labels)\n",
    "print(\"Best parameters:\", rand_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2, Exercise 3\n",
    "Try adding a transformer in the preparation pipeline to select only the most important attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train a model to determine what features are important. RandomForest gives this.\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom transformer\n",
    "#use feature importances to select top N features\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TopFeatures(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self, feature_importances, topNFeatures):\n",
    "    self.feature_importances = feature_importances\n",
    "    self.topNFeatures = topNFeatures\n",
    "    \n",
    "def fit(self, housing_prepared, y=None):\n",
    "  self.feature_indices_ = self.feature_importances.argsort()[-self.topNFeatures:]\n",
    "  return self\n",
    "\n",
    "def transform(self, housing_prepared):\n",
    "  return housing_prepared[:self.feature_indices_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformer --> Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#get feature instances from trained RandomForestRegressor above\n",
    "feature_importances = forest_reg.feature_importances_\n",
    "\n",
    "topNFeatures = 5\n",
    "\n",
    "pipe = Pipeline([('preparation', full_pipeline()), ('feature_selection', TopFeatures(feature_importances, topNFeatures))])\n",
    "\n",
    "#fit and transform data\n",
    "housing_prepared_topNFeatures = pipe.fit_transform(housing_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2, Exercise 4\n",
    "Try creating a single pipeline that does the full data preparation plus the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_pipe = Pipeline([('preparation', full_pipeline()), \n",
    "('feature_selection', TopFeatures(feature_importances, topNFeatures))\n",
    "('sup_vec', SVR(**rand_search.best_params_))\n",
    "])\n",
    "\n",
    "single_pipe.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2, Exercise 5\n",
    "Automatically explore some preparation options using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "preprocessing_pipe_2_5 = Pipeline([\n",
    "  ('scaler', StandardScaler()),\n",
    "  ('classifier', )\n",
    "  ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
