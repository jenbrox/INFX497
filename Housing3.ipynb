{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea62209",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Chapter Three\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db196381-59f2-402c-b50a-c3a421562c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"my path is \", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d24105",
   "metadata": {},
   "source": [
    "### Setup 0⃣\n",
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb443764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0594c56d",
   "metadata": {},
   "source": [
    "## Machine Learning Project Checklist\n",
    " \n",
    "1. Look at the big picture.\n",
    "2. Get the data.\n",
    "3. Discover and visualize the data to gain insights.\n",
    "4. Prepare the data for Machine Learning algorithms.\n",
    "5. Select a model and train it.\n",
    "6. Fine-tune your model.\n",
    "7. Present your solution.\n",
    "8. Launch, monitor, and maintain your system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe0cc7c-7858-4160-a09e-5b0ec48eaa16",
   "metadata": {},
   "source": [
    "# Chapter 3\n",
    "Using MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b61cb0-ae77-4b8b-a431-a4c0237bd751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function to fetch datasets from OpenML, an online repository of well-documented datasets\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Fetch MNIST dataset containing handwritten digits with 784 features\n",
    "mnist = fetch_openml('mnist_784', version=1,as_frame=False)\n",
    "\n",
    "# keys of the MNIST dataset. object contains the data, target (labels), a description of the dataset, and other metadata.\n",
    "# keys: 'data': the feature matrix,'target': the label array,'feature_names': the names of the features,'DESCR': a full description of the dataset,\n",
    "# 'categories': the category labels (for categorical features)\n",
    "mnist_keys = mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ea433d-3c1d-4897-ab04-3a394362cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the structure of the data (X) and labels (y)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "#return the dimensions of the array containing the image data\n",
    "X.shape\n",
    "#return the dimensions of the array containing the labels for the images\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc25f095-a81f-4163-9879-2147d6cb32e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#an instance’s feature vector, reshape it to a 28 × 28 array, and display it using Matplotlib’s imshow() function:\n",
    "some_digit = X[0]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap=\"binary\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc165995-1c55-47e4-8e19-09b8209335a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#double check the label to make sure it is what we think it is\n",
    "y[0]\n",
    "#cast the string label to an int since that is what most ML algorithms expect\n",
    "y = y.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faddc09d-f6a0-4cf7-b4a7-968adc27ae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a test set first (for this datsset using already given split)\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6c677-8043-4a2e-801d-0b39b29c1e92",
   "metadata": {},
   "source": [
    "## Training a Binary Classifier\n",
    "Distinguishes between two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a537f-a5f5-43ce-ad1c-6664a4d93a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target vectors for this classification task\n",
    "y_train_5 = (y_train == 5) # True for all 5s, False for all other digits\n",
    "y_test_5 = (y_test == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4feca3b-7875-46e1-9456-82cc99500d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a classifier and train it\n",
    "# stochastic gradient descent classifier, train it to differentiate between the digit '5' and other digits in the MNIST dataset \n",
    "#The X_train contains the training data features, while y_train_5 is the target variable for the binary classification task\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#random_state gives you reproducible results\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "#detect images of the number 5\n",
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53be1e58-5a1c-40fb-b293-009c8702a3e3",
   "metadata": {},
   "source": [
    "## Performance Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49108cc-59df-49da-ac2f-cc749c72a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#meausry accuracy Using Cross-Validation\n",
    "#evaluates the model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "skfolds = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    " clone_clf = clone(sgd_clf)\n",
    " X_train_folds = X_train[train_index]\n",
    " y_train_folds = y_train_5[train_index]\n",
    " X_test_fold = X_train[test_index]\n",
    " y_test_fold = y_train_5[test_index]\n",
    " clone_clf.fit(X_train_folds, y_train_folds)\n",
    " y_pred = clone_clf.predict(X_test_fold)\n",
    " n_correct = sum(y_pred == y_test_fold)\n",
    " print(n_correct / len(y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97624b2d-7eca-4235-b01a-14ce275752b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use cross_val_score() to evaluate SGDClassifier. using K-fold cross-validation with three folds, ie splitting the training set into K folds \n",
    "#then making predictions and evaluating them on each fold using a model trained on the remaining folds\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "# Above 93% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a6080-9d27-415c-91ce-162e3546ca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#very dumb classifier that just classifies every single image in the “not-5” class:\n",
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    " def fit(self, X, y=None):\n",
    "     return self\n",
    " def predict(self, X):\n",
    "     return np.zeros((len(X), 1), dtype=bool)\n",
    "    \n",
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "#90% accuracy bc about 10% of the images are 5, so not too hard to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c855880-4bd9-45ef-8052-e53bdb8aaac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Great example as to why accuracy is not the preferred performance measure for classifiers\n",
    "#A better way is a Confusion Matrix\n",
    "#like the cross_val_score() function, cross_val_predict() performs K-fold cross-validation, but instead of returning the evaluation scores, \n",
    "#it returns the predictions made on each test fold.\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
    "# get the confusion matrix using the confusion_matrix() function. pass it the target classes (y_train_5) and the predicted classes (y_train_pred):\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train_5, y_train_pred)\n",
    "#Each row in a confusion matrix represents an actual class, while each column represents a predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6609fc5f-b5bd-4f83-9674-f25197f05723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comute classifier metrics, measurements used to evaluate the performance of a classification model\n",
    "#compute the harmonic mean of precision and recall/(F_1) \n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cebc34-88c3-49b7-9086-b81809c17409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this decision_function method returns the decision score for each instance\n",
    "y_scores = sgd_clf.decision_function([some_digit])\n",
    "y_scores\n",
    "threshold = 0\n",
    "y_some_digit_pred = (y_scores > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f83279-4349-4d14-9a55-ddaf5b680d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The SGDClassifier uses a threshold equal to 0, so the previous code returns the same result as the predict() method (i.e., True). \n",
    "#raise the threshold:\n",
    "threshold = 8000\n",
    "y_some_digit_pred = (y_scores > threshold)\n",
    "y_some_digit_pred\n",
    "#raising threshold reduces recall and classifier no longer detects it as a 5 as it did when threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bd479c-e513-412d-9a37-9f62a035bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decdide what threshold to use:\n",
    "#use cross_val_predict() function to get the scores of all instances in the training set,\n",
    "#specify that you want to return decision scores instead of predictions:\n",
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=\"decision_function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7098509-93e7-48ba-b036-614f4a3e6848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then with these scores, use the precision_recall_curve() function to compute precision and recall for all possible thresholds:\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae077e9-e83f-4398-b267-ba5211387005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib to plot precision and recall as functions of the threshold value \n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.legend(loc=\"center right\", fontsize=16) \n",
    "    plt.xlabel(\"Threshold\", fontsize=16)        \n",
    "    plt.grid(True)                              \n",
    "    plt.axis([-50000, 50000, 0, 1])            \n",
    "\n",
    "recall_90_precision = recalls[np.argmax(precisions >= 0.90)]\n",
    "threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]\n",
    "\n",
    "plt.figure(figsize=(8, 4))                                                                 \n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.plot([threshold_90_precision, threshold_90_precision], [0., 0.9], \"r:\")                 \n",
    "plt.plot([-50000, threshold_90_precision], [0.9, 0.9], \"r:\")                                \n",
    "plt.plot([-50000, threshold_90_precision], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "plt.plot([threshold_90_precision], [0.9], \"ro\")                                            \n",
    "plt.plot([threshold_90_precision], [recall_90_precision], \"ro\")                            \n",
    "plt.show()\n",
    "\n",
    "    \n",
    "#     [...] # highlight the threshold and add the legend, axis label, and grid\n",
    "#     # Highlight the threshold (e.g., with a red vertical line at the chosen threshold value)\n",
    "#     chosen_threshold = 5000\n",
    "#     plt.plot([chosen_threshold, chosen_threshold], [0, 1], \"r:\")     # Threshold line\n",
    "#     plt.annotate('Threshold', xy=(chosen_threshold, 0.5), xytext=(chosen_threshold+500, 0.5), arrowprops=dict(facecolor='black', shrink=0.05), )\n",
    "#     plt.xlabel(\"Threshold\")                                           # x-axis label\n",
    "#     plt.ylabel(\"Score\")                                               # y-axis label\n",
    "#     plt.legend()                                                      # Show legend\n",
    "#     plt.grid(True)                                                    # Turn on the grid\n",
    "#     plt.xlim([-50000, 50000]) \n",
    "\n",
    "# plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72a2f68-eb14-4962-bb4d-d9e964396d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_train_pred == (y_scores > 0)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad31b99-c037-439d-81af-dd633d18f774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_vs_recall(precisions, recalls):\n",
    "    plt.plot(recalls, precisions, \"b-\", linewidth=2)\n",
    "    plt.xlabel(\"Recall\", fontsize=16)\n",
    "    plt.ylabel(\"Precision\", fontsize=16)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_precision_vs_recall(precisions, recalls)\n",
    "plt.plot([recall_90_precision, recall_90_precision], [0., 0.9], \"r:\")\n",
    "plt.plot([0.0, recall_90_precision], [0.9, 0.9], \"r:\")\n",
    "plt.plot([recall_90_precision], [0.9], \"ro\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bc61fb-fc54-4c15-86ea-d7d73cd45fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if we want a 90% precision\n",
    "threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c3d9dc-cb8d-48a8-970d-7beac621dc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_90_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9605e1-d7b6-4f7d-ac40-b86ccde89c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to make predicitions instead of calling classifier's predicti() method\n",
    "y_train_pred_90 = (y_scores >= threshold_90_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cf2ba5-abe0-4b3b-83ab-1db8f5aa45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check precision\n",
    "precision_score(y_train_5, y_train_pred_90)\n",
    "#this confirms 90% precision we wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5927c5-52f7-4151-a24b-ba227fc29b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check recall\n",
    "recall_score(y_train_5, y_train_pred_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b998d8-43c5-4334-a6b6-72035951c7c4",
   "metadata": {},
   "source": [
    "## The ROC Curve\n",
    "Receiver Operating Characteristic. Another classifier metric used with binary classifiers. Plots TPR (recall) against FPR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521ad5b-e7e9-43a3-9bfc-9e65d5a75c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute TPR and FPR\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc07ce-5c44-449e-bf16-46ab7343c216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#then plot TPR and FPR\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--') # dashed diagonal\n",
    "    plt.axis([0, 1, 0, 1])                                    \n",
    "    plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) \n",
    "    plt.ylabel('True Positive Rate (Recall)', fontsize=16)    \n",
    "    plt.grid(True)                                            \n",
    "\n",
    "plt.figure(figsize=(8, 6))                                    \n",
    "plot_roc_curve(fpr, tpr)\n",
    "fpr_90 = fpr[np.argmax(tpr >= recall_90_precision)]           \n",
    "plt.plot([fpr_90, fpr_90], [0., recall_90_precision], \"r:\")   \n",
    "plt.plot([0.0, fpr_90], [recall_90_precision, recall_90_precision], \"r:\")  \n",
    "plt.plot([fpr_90], [recall_90_precision], \"ro\")                                                  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983d2045-2fc1-4d5e-a71e-5559dafffd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The more your ROC line is above the randoming guessing line the better. Use AUC to calculate this. 0.5 is purely random, 1 is perfect\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44bedf-fa8b-48b0-a556-f0d1687f6901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RandomForestClassifer and compare it's ROC curve and ROC AUC score to the SGD Classifier\n",
    "#The predict_proba() method returns an array containing a row per instance and a column per class, each containing the probability that the given instance belongs to the given class (e.g., 70% chance that the image represents a 5):\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3,\n",
    "                                    method=\"predict_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aca476a-ec4a-443b-b049-a549e8d1aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc_curve() function expects labels and scores, but instead of scores you can give it class probabilities. Let’s use the positive class’s probability as the score:\n",
    "y_scores_forest = y_probas_forest[:, 1] # score = proba of positive class\n",
    "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5,y_scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd57d16-0821-48e1-be3e-3158b8411a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot ROC curve  to see how they compare\n",
    "recall_for_forest = tpr_forest[np.argmax(fpr_forest >= fpr_90)]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, \"b:\", linewidth=2, label=\"SGD\")\n",
    "plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\n",
    "plt.plot([fpr_90, fpr_90], [0., recall_90_precision], \"r:\")\n",
    "plt.plot([0.0, fpr_90], [recall_90_precision, recall_90_precision], \"r:\")\n",
    "plt.plot([fpr_90], [recall_90_precision], \"ro\")\n",
    "plt.plot([fpr_90, fpr_90], [0., recall_for_forest], \"r:\")\n",
    "plt.plot([fpr_90], [recall_for_forest], \"ro\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"lower right\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa18220-df76-4ee8-876e-6fcedd8f45d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest is better bc ROC Curve looks much better than SGDClassifier's as it comes much closer to top-left corner. As a result its ROC AUC score is also signifigantly better\n",
    "roc_auc_score(y_train_5, y_scores_forest)\n",
    "#99% precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc1fcb0-8d67-4822-89db-26e301b8cbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3)\n",
    "precision_score(y_train_5, y_train_pred_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b3af9-1e44-4fd7-b12c-f5cc0df7c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_5, y_train_pred_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033fa048-50cb-4320-a646-c15dede5643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c84592b-33e7-4d87-afb2-998617c13a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run a Support Vector Machine CLassifier (this algorithm is strictly binary)\n",
    "#trains the SVC on the training set using the 0-9 target classes, not 5 versus the rest (y_train_5)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(gamma=\"auto\", random_state=42)\n",
    "svm_clf.fit(X_train[:1000], y_train[:1000]) # y_train, not y_train_5\n",
    "svm_clf.predict([some_digit])\n",
    "#this actually trained 45 binary classifiers,got their deicision scores for the image, and selected teh class that won the most duels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402322b9-6adc-48f2-aee0-1fa63f11ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shown by returning the scores per instance\n",
    "some_digit_scores = svm_clf.decision_function([some_digit])\n",
    "some_digit_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3d47a3-628e-4b49-8a82-cf4a062c0563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#highest score is one correspeonding to class 5\n",
    "np.argmax(some_digit_scores)\n",
    "svm_clf.classes_\n",
    "svm_clf.classes_[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea24c2d-aa35-48a8-bbae-138c961ed104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to force skikit to use a certain classifier (OvO, OvR, etc\n",
    "#this creates a multiclass classifier using the OvR strategy based on SVR\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "ovr_clf = OneVsRestClassifier(SVC(gamma=\"auto\", random_state=42))\n",
    "ovr_clf.fit(X_train[:1000], y_train[:1000])\n",
    "ovr_clf.predict([some_digit])\n",
    "len(ovr_clf.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5318d590-2be3-4531-b312-7b08a12007a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or using the SGDClassifier\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac95fb-5004-4136-93d2-836e64b24c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since Skikit used the OvR strategy, there are now 10 classes and it trained 10 binary classifiers. THis now returns one value per class\n",
    "#score that SGD Classifier assigned to each class\n",
    "sgd_clf.decision_function([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672f1dce-8518-482e-a9e1-0e20666e1ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c0fcf2-d2c0-47ee-87d2-60d6cf935884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca79cb4f-dbf3-4030-81e2-738348a08882",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65139672-a715-4ca8-a121-6f8e216da315",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e10c16-4837-455c-ae87-f3fdc6e7a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since sklearn 0.22, you can use sklearn.metrics.plot_confusion_matrix()\n",
    "def plot_confusion_matrix(matrix):\n",
    "    \"\"\"If you prefer color and a colorbar\"\"\"\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(matrix)\n",
    "    fig.colorbar(cax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc1fe7-fcb7-42c5-955f-cb3bc6b9c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "save_fig(\"confusion_matrix_plot\", tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fead3d-8f17-4f87-811e-6be225081b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec405b1d-dfff-4a97-80d6-14c0ac462907",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "save_fig(\"confusion_matrix_errors_plot\", tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd930ae-3ab7-437b-b33d-9b0a34ab3632",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_a, cl_b = 3, 5\n",
    "X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]\n",
    "X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]\n",
    "X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]\n",
    "X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(221); plot_digits(X_aa[:25], images_per_row=5)\n",
    "plt.subplot(222); plot_digits(X_ab[:25], images_per_row=5)\n",
    "plt.subplot(223); plot_digits(X_ba[:25], images_per_row=5)\n",
    "plt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)\n",
    "save_fig(\"error_analysis_digits_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9067ed3-2b8f-442a-96ca-bd15071e8842",
   "metadata": {},
   "source": [
    "## Multilabel Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81ba21e-1825-4a2b-bea1-87383f62f858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "y_train_large = (y_train >= 7)\n",
    "y_train_odd = (y_train % 2 == 1)\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd]\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b15389-6967-4636-b886-63afb68cbeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad30779-0798-401e-81a8-0b02945bb473",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)\n",
    "f1_score(y_multilabel, y_train_knn_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f94cc2-4dc9-4a37-a95b-aba3d7265f24",
   "metadata": {},
   "source": [
    "## Multioutput Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898e19fb-3831-4faa-8c83-b56e9ec99413",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.randint(0, 100, (len(X_train), 784))\n",
    "X_train_mod = X_train + noise\n",
    "noise = np.random.randint(0, 100, (len(X_test), 784))\n",
    "X_test_mod = X_test + noise\n",
    "y_train_mod = X_train\n",
    "y_test_mod = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b266c00-b72a-4e13-b6ca-1d0a80d48671",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_index = 0\n",
    "plt.subplot(121); plot_digit(X_test_mod[some_index])\n",
    "plt.subplot(122); plot_digit(y_test_mod[some_index])\n",
    "save_fig(\"noisy_digit_example_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3961e6-0c97-481b-bb1f-58bf74ca2c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf.fit(X_train_mod, y_train_mod)\n",
    "clean_digit = knn_clf.predict([X_test_mod[some_index]])\n",
    "plot_digit(clean_digit)\n",
    "save_fig(\"cleaned_digit_example_plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec763c89-6511-4eb3-9e26-ad501fab92d4",
   "metadata": {},
   "source": [
    "# Chapter 3, Exercise 1\n",
    " Try to build a classifier for the MNIST dataset that achieves over 97% accuracy\n",
    "on the test set. Hint: the KNeighborsClassifier works quite well for this task;\n",
    "you just need to find good hyperparameter values (try a grid search on the\n",
    "weights and n_neighbors hyperparameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dffbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV will use cross-validation to evaluate all possible combinations of hyperparameters so you don't have to tinker\n",
    "# Import the GridSearchCV class for hyperparameter tuning using cross-validation.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a parameter grid to search over. For the KNeighborsClassifier, we're exploring\n",
    "# two hyperparameters: 'weights' (with options 'uniform' and 'distance') and 'n_neighbors'\n",
    "# (with options 3, 4, and 5). This creates a grid of parameter combinations to test.\n",
    "param_grid = [{'weights': [\"uniform\", \"distance\"], 'n_neighbors': [3, 4, 5]}]\n",
    "\n",
    "# Initialize Classifier. This is the model we're tuning.\n",
    "knn_clf = KNeighborsClassifier()\n",
    "# Set up GridSearchCV with the classifier (knn_clf), the parameter grid (param_grid),\n",
    "# and a 5-fold cross-validation (cv=5). Verbose=3 increases the messages printed\n",
    "# to the console so you can track the progress of the search.\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, cv=5, verbose=3)\n",
    "# Fit the GridSearchCV to the training data. This will test all combinations\n",
    "# of parameters in the grid, using 5-fold cross-validation for each combination.\n",
    "# It selects the best combination based on cross-validated performance.\n",
    "grid_search.fit(X_train, y_train)\n",
    "# After fitting, grid_search holds the best model and parameters\n",
    "grid_search_clf.best_score_\n",
    "#best parameters\n",
    "grid_search_clf.best_params_\n",
    "#best model\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ab254-f6e7-4828-9108-b0093a288347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function to compute accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Use the best model found by GridSearchCV to make predictions on the test set.\n",
    "# This uses the model with the optimal hyperparameters found during the grid search.\n",
    "y_pred = grid_search.predict(X_test)\n",
    "# Calculate the accuracy of the model on the test set by comparing the predicted labels (y_pred)\n",
    "# to the true labels (y_test). The accuracy score is the fraction of correct predictions over\n",
    "# the total number of predictions, expressed as a float between 0 and 1, where 1 means perfect accuracy.\n",
    "accuracy_score(y_test, y_pred)\n",
    "# The variable 'accuracy' now holds the accuracy score of the best model found by GridSearchCV\n",
    "# when evaluated on unseen test data. This gives an estimate of the model's generalization ability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6200408-12b3-492f-994e-fdfc911a8b82",
   "metadata": {},
   "source": [
    "# Chapter 3, Exercise 2\n",
    " Write a function that can shift an MNIST image in any direction (left, right, up,\n",
    "or down) by one pixel.5 Then, for each image in the training set, create four shif‐\n",
    "ted copies (one per direction) and add them to the training set. Finally, train your\n",
    "best model on this expanded training set and measure its accuracy on the test set.\n",
    "You should observe that your model performs even better now! This technique of\n",
    "artificially growing the training set is called data augmentation or training set\n",
    "expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62f9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to shift an image by dx (delta x) and dy (delta y) pixels.\n",
    "# This can be used for data augmentation, to create more training data from the existing images\n",
    "# by slightly shifting them in any direction.\n",
    "def shift_image(image, dx, dy):\n",
    "    # Reshape the flat image array into a 28x28 matrix, as the original MNIST images are 28x28 pixels.\n",
    "    image = image.reshape((28, 28))\n",
    "    # Use the 'shift' function from scipy.ndimage.interpolation to shift the image.\n",
    "    # 'dy' and 'dx' specify the shift amount along the y and x axes, respectively.\n",
    "    # 'cval' specifies the value to fill past edges of input if mode is 'constant'. Here it's set to 0, \n",
    "    # meaning the empty space created by the shift will be filled with 0s (black).\n",
    "    # 'mode' specifies how the input array is extended beyond its boundaries. 'constant' means pad with a constant value.\n",
    "    shifted_image = shift(image, [dy, dx], cval=0, mode=\"constant\")\n",
    "    # Reshape the shifted image back to a flat array before returning it.\n",
    "    return shifted_image.reshape([-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bcea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = X_train[1000]\n",
    "shifted_image_down = shift_image(image, 0, 5)\n",
    "shifted_image_left = shift_image(image, -5, 0)\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(131)\n",
    "plt.title(\"Original\", fontsize=14)\n",
    "plt.imshow(image.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "plt.subplot(132)\n",
    "plt.title(\"Shifted down\", fontsize=14)\n",
    "plt.imshow(shifted_image_down.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "plt.subplot(133)\n",
    "plt.title(\"Shifted left\", fontsize=14)\n",
    "plt.imshow(shifted_image_left.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f6e62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to hold the augmented training data and labels.\n",
    "# Copy original training images.\n",
    "X_train_augmented = [image for image in X_train]\n",
    "# Copy original training labels.\n",
    "y_train_augmented = [label for label in y_train]\n",
    "\n",
    "# Loop over a set of directions to shift the images: right (1, 0), left (-1, 0), down (0, 1), and up (0, -1).\n",
    "for dx, dy in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n",
    "    # For each direction, shift each image in the training set and add the shifted image to the augmented dataset.\n",
    "    \n",
    "    for image, label in zip(X_train, y_train):\n",
    "        # Shift the image using the previously defined function.\n",
    "        shifted_image = shift_image(image, dx, dy)  \n",
    "# Add the shifted image to the augmented dataset.\n",
    "        X_train_augmented.append(shift_image(image, dx, dy))\n",
    "        # The label remains the same, as the image content hasn't changed category.\n",
    "        y_train_augmented.append(label)\n",
    "# Convert the augmented datasets from lists to numpy arrays for easier handling in machine learning models.\n",
    "X_train_augmented = np.array(X_train_augmented)\n",
    "y_train_augmented = np.array(y_train_augmented)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298ad44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate a random permutation of indices based on the length of the augmented training set.\n",
    "shuffle_idx = np.random.permutation(len(X_train_augmented))\n",
    "\n",
    "# Reorder the augmented training images and labels according to the random permutation.\n",
    "# This ensures that the data is shuffled, mixing the original and augmented images,\n",
    "# which is beneficial for training models to prevent any order bias.\n",
    "X_train_augmented = X_train_augmented[shuffle_idx]\n",
    "y_train_augmented = y_train_augmented[shuffle_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3705622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier(**grid_search.best_params_)\n",
    "knn_clf.fit(X_train_augmented, y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07040435",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aee5921-b20d-4466-9352-857187a3e6a2",
   "metadata": {},
   "source": [
    "# Chapter 3, Exercise 3\n",
    " Tackle the Titanic dataset. A great place to start is on Kaggle (https://www.kaggle.com/c/titanic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60c6824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "TITANIC_PATH = os.path.join(\"datasets\", \"titanic\")\n",
    "DOWNLOAD_URL = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/titanic/\"\n",
    "\n",
    "def fetch_titanic_data(url=DOWNLOAD_URL, path=TITANIC_PATH):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "    for filename in (\"train.csv\", \"test.csv\"):\n",
    "        filepath = os.path.join(path, filename)\n",
    "        if not os.path.isfile(filepath):\n",
    "            print(\"Downloading\", filename)\n",
    "            urllib.request.urlretrieve(url + filename, filepath)\n",
    "\n",
    "fetch_titanic_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f93771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_titanic_data(filename, titanic_path=TITANIC_PATH):\n",
    "    csv_path = os.path.join(titanic_path, filename)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de4d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_titanic_data(\"train.csv\")\n",
    "test_data = load_titanic_data(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eac105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at attributes\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694776ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set PassengerId as index column\n",
    "train_data = train_data.set_index(\"PassengerId\")\n",
    "test_data = test_data.set_index(\"PassengerId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506cefe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get more info - any missing data?\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e2556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#median age of females\n",
    "train_data[train_data[\"Sex\"]==\"female\"][\"Age\"].median()\n",
    "#to replace null Age attributes with median age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf852a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at numerical attributes\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a49d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check in boolean\n",
    "train_data[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752ef049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at categorical attributes\n",
    "train_data[\"Pclass\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe394f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e251eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94132535",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build our preprocessing pipelines, starting with the pipeline for numerical attributes:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65444e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the pipeline for the categorical attributes:\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0769506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the two\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "cat_attribs = [\"Pclass\", \"Sex\", \"Embarked\"]\n",
    "\n",
    "preprocess_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", cat_pipeline, cat_attribs),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4af0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess_pipeline.fit_transform(\n",
    "    train_data[num_attribs + cat_attribs])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86b504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get labels\n",
    "y_train = train_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9edb26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "forest_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e66a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "X_test = preprocess_pipeline.transform(test_data[num_attribs + cat_attribs])\n",
    "y_pred = forest_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d78596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use cross validation to determine how good our model is\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "forest_scores = cross_val_score(forest_clf, X_train, y_train, cv=10)\n",
    "forest_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba51ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to get more accurate classifier with SvC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(gamma=\"auto\")\n",
    "svm_scores = cross_val_score(svm_clf, X_train, y_train, cv=10)\n",
    "svm_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745adedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the ten scores\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot([1]*10, svm_scores, \".\")\n",
    "plt.plot([2]*10, forest_scores, \".\")\n",
    "plt.boxplot([svm_scores, forest_scores], labels=(\"SVM\",\"Random Forest\"))\n",
    "plt.ylabel(\"Accuracy\", fontsize=14)\n",
    "plt.show()\n",
    "#can further improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c4a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"AgeBucket\"] = train_data[\"Age\"] // 15 * 15\n",
    "train_data[[\"AgeBucket\", \"Survived\"]].groupby(['AgeBucket']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4332df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"RelativesOnboard\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\n",
    "train_data[[\"RelativesOnboard\", \"Survived\"]].groupby(['RelativesOnboard']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3157e7-4878-465d-a8f3-a9b6da66dc3b",
   "metadata": {},
   "source": [
    "# Chapter 3, Exercise 4\n",
    "Build a spam classifier (a more challenging exercise):\n",
    "\n",
    "• Download examples of spam and ham from Apache SpamAssassin’s public\n",
    "dataset (https://homl.info/spamassassin)..\n",
    "\n",
    "• Unzip the datasets and familiarize yourself with the data format.\n",
    "\n",
    "• Split the datasets into a training set and a test set.\n",
    "\n",
    "• Write a data preparation pipeline to convert each email into a feature vector.\n",
    "Your preparation pipeline should transform an email into a (sparse) vector that\n",
    "indicates the presence or absence of each possible word. For example, if all\n",
    "emails only ever contain four words, “Hello,” “how,” “are,” “you,” then the email\n",
    "“Hello you Hello Hello you” would be converted into a vector [1, 0, 0, 1]\n",
    "(meaning [“Hello” is present, “how” is absent, “are” is absent, “you” is\n",
    "present]), or [3, 0, 0, 2] if you prefer to count the number of occurrences of\n",
    "each word.\n",
    "\n",
    "You may want to add hyperparameters to your preparation pipeline to control\n",
    "whether or not to strip off email headers, convert each email to lowercase,\n",
    "remove punctuation, replace all URLs with “URL,” replace all numbers with\n",
    "“NUMBER,” or even perform stemming (i.e., trim off word endings; there are\n",
    "Python libraries available to do this).\n",
    "Finally, try out several classifiers and see if you can build a great spam classi‐\n",
    "fier, with both high recall and high precision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d365569-9b5b-4e04-be71-b6af960168ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrive data\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "DOWNLOAD_ROOT = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
    "HAM_URL = DOWNLOAD_ROOT + \"20030228_easy_ham.tar.bz2\"\n",
    "SPAM_URL = DOWNLOAD_ROOT + \"20030228_spam.tar.bz2\"\n",
    "SPAM_PATH = os.path.join(\"datasets\", \"spam\")\n",
    "\n",
    "def fetch_spam_data(ham_url=HAM_URL, spam_url=SPAM_URL, spam_path=SPAM_PATH):\n",
    "    if not os.path.isdir(spam_path):\n",
    "        os.makedirs(spam_path)\n",
    "    for filename, url in ((\"ham.tar.bz2\", ham_url), (\"spam.tar.bz2\", spam_url)):\n",
    "        path = os.path.join(spam_path, filename)\n",
    "        if not os.path.isfile(path):\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "        tar_bz2_file = tarfile.open(path)\n",
    "        tar_bz2_file.extractall(path=spam_path)\n",
    "        tar_bz2_file.close()\n",
    "        \n",
    "fetch_spam_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341d93b5-e51f-4f80-9bcd-d351ee8bb73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download emails\n",
    "HAM_DIR = os.path.join(SPAM_PATH, \"easy_ham\")\n",
    "SPAM_DIR = os.path.join(SPAM_PATH, \"spam\")\n",
    "ham_filenames = [name for name in sorted(os.listdir(HAM_DIR)) if len(name) > 20]\n",
    "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8093e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ham_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spam_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203d490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use Python's email module to parse these emails (this handles headers, encoding, etc\n",
    "import email\n",
    "import email.policy\n",
    "\n",
    "def load_email(is_spam, filename, spam_path=SPAM_PATH):\n",
    "    directory = \"spam\" if is_spam else \"easy_ham\"\n",
    "    with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdedfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_emails = [load_email(is_spam=False, filename=name) for name in ham_filenames]\n",
    "spam_emails = [load_email(is_spam=True, filename=name) for name in spam_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb99f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at one example of ham and one example of spam, to get a feel of what the data looks like:\n",
    "print(ham_emails[1].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f03d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same for spam emails\n",
    "print(spam_emails[6].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some emails are actually multipart, with images and attachments. Look at the various types of structures we have:\n",
    "def get_email_structure(email):\n",
    "    if isinstance(email, str):\n",
    "        return email\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload, list):\n",
    "        return \"multipart({})\".format(\", \".join([\n",
    "            get_email_structure(sub_email)\n",
    "            for sub_email in payload\n",
    "        ]))\n",
    "    else:\n",
    "        return email.get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755edeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7413fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures_counter(ham_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2196bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures_counter(spam_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2134133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the email headers:\n",
    "for header, value in spam_emails[0].items():\n",
    "    print(header,\":\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04549400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#focus on the Subject header:\n",
    "spam_emails[0][\"Subject\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54a6319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split it into a training set and a test set:\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(ham_emails + spam_emails, dtype=object)\n",
    "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start writing the preprocessing functions. First,  a function to convert HTML to plain text.\n",
    "#The following function first drops the <head> section, then converts all <a> tags to the word HYPERLINK, then it gets rid of all HTML tags, leaving only the plain text. For readability, it also replaces multiple newlines with single newlines, and finally it unescapes html entities (such as &gt; or &nbsp;):\n",
    "import re\n",
    "from html import unescape\n",
    "\n",
    "def html_to_plain_text(html):\n",
    "    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<.*?>', '', text, flags=re.M | re.S)\n",
    "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
    "    return unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bb3cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HTML spam\n",
    "html_spam_emails = [email for email in X_train[y_train==1]\n",
    "                    if get_email_structure(email) == \"text/html\"]\n",
    "sample_html_spam = html_spam_emails[7]\n",
    "print(sample_html_spam.get_content().strip()[:1000], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67987c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resulting plain text\n",
    "print(html_to_plain_text(sample_html_spam.get_content())[:1000], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb59a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that takes an email as input and returns its content as plain text, no matter its format is:\n",
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if not ctype in (\"text/plain\", \"text/html\"):\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        except: # in case of encoding issues\n",
    "            content = str(part.get_payload())\n",
    "        if ctype == \"text/plain\":\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_plain_text(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07e0a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(email_to_text(sample_html_spam)[:100], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5d24fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming\n",
    "try:\n",
    "    import nltk\n",
    "\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\", \"Compulsive\"):\n",
    "        print(word, \"=>\", stemmer.stem(word))\n",
    "except ImportError:\n",
    "    print(\"Error: stemming requires the NLTK module.\")\n",
    "    stemmer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b25fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#way to replace URLs with the word \"URL\"\n",
    "%pip install -q -U urlextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29bd121",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import urlextract # may require an Internet connection to download root domain names\n",
    "    \n",
    "    url_extractor = urlextract.URLExtract()\n",
    "    print(url_extractor.find_urls(\"Will it detect github.com and https://youtu.be/7Pq-S557XQU?t=3m32s\"))\n",
    "except ImportError:\n",
    "    print(\"Error: replacing URLs requires the urlextract module.\")\n",
    "    url_extractor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True,\n",
    "                 replace_urls=True, replace_numbers=True, stemming=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            text = email_to_text(email) or \"\"\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.replace_urls and url_extractor is not None:\n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df4704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test transformer\n",
    "X_few = X_train[:3]\n",
    "X_few_wordcounts = EmailToWordCounterTransformer().fit_transform(X_few)\n",
    "X_few_wordcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6181cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert word counts to vectors by building  another transformer \n",
    "#whose fit() method will build the vocabulary (an ordered list of the most common words) and whose transform() method will use the vocabulary to convert word counts to vectors. The output is a sparse matrix.\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self, X, y=None):\n",
    "        total_count = Counter()\n",
    "        for word_count in X:\n",
    "            for word, count in word_count.items():\n",
    "                total_count[word] += min(count, 10)\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.vocabulary_ = {word: index + 1 for index, (word, count) in enumerate(most_common)}\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for row, word_count in enumerate(X):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word, 0))\n",
    "                data.append(count)\n",
    "        return csr_matrix((data, (rows, cols)), shape=(len(X), self.vocabulary_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588786dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
    "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)\n",
    "X_few_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de67eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_few_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34a2238",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_transformer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b64863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train our first spam classifier! Let's transform the whole dataset:\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocess_pipeline = Pipeline([\n",
    "    (\"email_to_wordcount\", EmailToWordCounterTransformer()),\n",
    "    (\"wordcount_to_vector\", WordCounterToVectorTransformer()),\n",
    "])\n",
    "\n",
    "X_train_transformed = preprocess_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bb34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42)\n",
    "score = cross_val_score(log_clf, X_train_transformed, y_train, cv=3, verbose=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a753ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the precision/recall we get on the test set:\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42)\n",
    "log_clf.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred = log_clf.predict(X_test_transformed)\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd6702c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
